{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Download data from Kaggle.com and perform an initial EDA.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* unclean_smartwatch_health_data.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* ydata-profiling EDA\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2 EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(DestinationFolder + \"/unclean_smartwatch_health_data.csv\")\n",
        "df = pd.DataFrame(data)\n",
        "df.head()\n",
        "\n",
        "# Change version variable to store outputs in different folder\n",
        "version = \"v1\"\n",
        "\n",
        "OutputFolder = f\"outputs/{version}/\"\n",
        "if \"outputs\" in os.listdir(current_dir):\n",
        "    if version not in os.listdir(current_dir + \"/outputs\"):\n",
        "        os.mkdir(OutputFolder)\n",
        "else:\n",
        "    os.makedirs(OutputFolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 2 Normality, Skewness and Kurtosis Improvement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before imputing the rest of the data, im going to try improving the normal distribution of the variables, as this decides wether you use the median or the mean for imputation of numerics. I can now test all numerical columns together after fixing the data types.\n",
        "\n",
        "Will do QQ plots with a BoxCox transformer with before and afters to see what the normality is like for the 3 numeric data types we can test, and then possibly improve skewness, kurtosis and normality with a boxcox with the aim to impute the most variables we can with the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Heart Rate (BPM) min: 40.0, max: 296.5939695131042\n",
            "Blood Oxygen Level (%) min: 90.79120814564097, max: 100.0\n",
            "Step Count min: 0.9101380609604088, max: 62486.690753464914\n",
            "Sleep Duration (hours) min: -0.1944527906201543, max: 12.140232872862926\n",
            "Stress Level min: 1, max: 11\n"
          ]
        }
      ],
      "source": [
        "# check min and max for numeric variables to see if boxcox is suitable\n",
        "for col in df_processed:\n",
        "    if df_processed[col].dtype == \"float64\" or df_processed[col].dtype == \"int64\":\n",
        "        print(f\"{col} min: {df_processed[col].min()}, max: {df_processed[col].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Some of the variables in the dataset contain NaN. Check and remove those before using this transformer.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[22], line 22\u001b[0m\n",
            "\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# We set the pipeline with this transformer: vt.BoxCoxTransformer().\u001b[39;00m\n",
            "\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Then we .fit_transform() the pipeline, assigning the result to df_transformed\u001b[39;00m\n",
            "\u001b[1;32m     18\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n",
            "\u001b[1;32m     19\u001b[0m       ( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m, vt\u001b[38;5;241m.\u001b[39mBoxCoxTransformer() ) \u001b[38;5;66;03m# Main difference here\u001b[39;00m\n",
            "\u001b[1;32m     20\u001b[0m   ])\n",
            "\u001b[0;32m---> 22\u001b[0m df_transformed \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_numeric\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_transformed\u001b[38;5;241m.\u001b[39mhead())\n",
            "\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_distributions_before_and_after_applying_transformer\u001b[39m(df, df_transformed, method):\n",
            "\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
            "\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
            "\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
            "\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
            "\u001b[1;32m   1387\u001b[0m     )\n",
            "\u001b[1;32m   1388\u001b[0m ):\n",
            "\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/pipeline.py:730\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n",
            "\u001b[1;32m    724\u001b[0m last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n",
            "\u001b[1;32m    725\u001b[0m     step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n",
            "\u001b[1;32m    726\u001b[0m     step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n",
            "\u001b[1;32m    727\u001b[0m     all_params\u001b[38;5;241m=\u001b[39mparams,\n",
            "\u001b[1;32m    728\u001b[0m )\n",
            "\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "\u001b[0;32m--> 730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlast_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n",
            "\u001b[1;32m    731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtransform(\n",
            "\u001b[1;32m    735\u001b[0m         Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "\u001b[1;32m    736\u001b[0m     )\n",
            "\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n",
            "\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
            "\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n",
            "\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n",
            "\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n",
            "\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n",
            "\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n",
            "\u001b[1;32m    325\u001b[0m         )\n",
            "\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n",
            "\u001b[1;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n",
            "\u001b[1;32m    904\u001b[0m             (\n",
            "\u001b[1;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n",
            "\u001b[1;32m    914\u001b[0m         )\n",
            "\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n",
            "\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n",
            "\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n",
            "\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
            "\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/feature_engine/transformation/boxcox.py:138\u001b[0m, in \u001b[0;36mBoxCoxTransformer.fit\u001b[0;34m(self, X, y)\u001b[0m\n",
            "\u001b[1;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
            "\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mLearn the optimal lambda for the BoxCox transformation.\u001b[39;00m\n",
            "\u001b[1;32m    126\u001b[0m \n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    It is not needed in this transformer. You can pass y or None.\u001b[39;00m\n",
            "\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
            "\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# check input dataframe\u001b[39;00m\n",
            "\u001b[0;32m--> 138\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_dict_ \u001b[38;5;241m=\u001b[39m {}\n",
            "\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables_:\n",
            "\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/feature_engine/_base_transformers/base_numerical.py:68\u001b[0m, in \u001b[0;36mBaseNumericalTransformer.fit\u001b[0;34m(self, X)\u001b[0m\n",
            "\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables_ \u001b[38;5;241m=\u001b[39m check_numerical_variables(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables)\n",
            "\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# check if dataset contains na or inf\u001b[39;00m\n",
            "\u001b[0;32m---> 68\u001b[0m \u001b[43m_check_contains_na\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables_\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m     69\u001b[0m _check_contains_inf(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables_)\n",
            "\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# save input features\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m~/.local/lib/python3.12/site-packages/feature_engine/dataframe_checks.py:268\u001b[0m, in \u001b[0;36m_check_contains_na\u001b[0;34m(X, variables)\u001b[0m\n",
            "\u001b[1;32m    251\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
            "\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03mChecks if DataFrame contains null values in the selected columns.\u001b[39;00m\n",
            "\u001b[1;32m    253\u001b[0m \n",
            "\u001b[0;32m   (...)\u001b[0m\n",
            "\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    If the variable(s) contain null values.\u001b[39;00m\n",
            "\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
            "\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X[variables]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many():\n",
            "\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
            "\u001b[1;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome of the variables in the dataset contain NaN. Check and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremove those before using this transformer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;32m    271\u001b[0m     )\n",
            "\n",
            "\u001b[0;31mValueError\u001b[0m: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer."
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "import seaborn as sns\n",
        "import pingouin as pg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_numeric = df_processed.select_dtypes(include=['float64','int64'])\n",
        "df_numeric.head()\n",
        "\n",
        "def calculate_skew_kurtosis(df,col, moment):\n",
        "  print(f\"{moment}  | skewness: {df[col].skew().round(2)} | kurtosis: {df[col].kurtosis().round(2)}\")\n",
        "\n",
        "\n",
        "# We set the pipeline with this transformer: vt.BoxCoxTransformer().\n",
        "# Then we .fit_transform() the pipeline, assigning the result to df_transformed\n",
        "\n",
        "pipeline = Pipeline([\n",
        "      ( 'log', vt.BoxCoxTransformer() ) # Main difference here\n",
        "  ])\n",
        "\n",
        "df_transformed = pipeline.fit_transform(df_numeric)\n",
        "print(df_transformed.head())\n",
        "\n",
        "def compare_distributions_before_and_after_applying_transformer(df, df_transformed, method):\n",
        "\n",
        "  for col in df.columns:\n",
        "    print(f\"*** {col} ***\")\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,8))\n",
        "\n",
        "    sns.histplot(data=df, x=col, kde=True, ax=axes[0,0])\n",
        "    axes[0,0].set_title(f'Before {method}')\n",
        "    pg.qqplot(df[col], dist='norm',ax=axes[0,1])\n",
        "    \n",
        "    sns.histplot(data=df_transformed, x=col, kde=True, ax=axes[1,0])\n",
        "    axes[1,0].set_title(f'After {method}')\n",
        "    pg.qqplot(df_transformed[col], dist='norm',ax=axes[1,1])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Save plot\n",
        "    plot_names = method + col + \".png\"\n",
        "    # Add a subfolder to the output folder for normality and skewness improvement plots\n",
        "    NormalitySkewness = OutputFolder + \"norm_skew_improvement/\"\n",
        "    if \"norm_skew_improvement\" not in os.listdir(OutputFolder):\n",
        "        os.mkdir(NormalitySkewness)\n",
        "    plot_dir = os.path.join(NormalitySkewness, plot_names)\n",
        "    fig.savefig(plot_dir)\n",
        "\n",
        "    calculate_skew_kurtosis(df,col, moment='before transformation')\n",
        "    calculate_skew_kurtosis(df_transformed,col, moment='after transformation')\n",
        "    print(\"\\n\")\n",
        "    \n",
        "compare_distributions_before_and_after_applying_transformer(df_numeric, df_transformed, method='BoxCoxTransformer')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Nov  7 2022, 16:45:55) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
